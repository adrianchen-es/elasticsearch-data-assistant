# Enhanced CI/CD with improved error messaging and comprehensive testing
name: Enhanced CI/CD Pipeline with Security & Observability

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.12'
  
  # Enhanced error reporting
  FORCE_COLOR: '1'
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  # Pre-flight checks with enhanced error messaging
  preflight-checks:
    name: ğŸš€ Pre-flight Validation
    runs-on: ubuntu-latest
    outputs:
      security-status: ${{ steps.security.outputs.status }}
      dependencies-status: ${{ steps.deps.outputs.status }}
      lint-status: ${{ steps.lint.outputs.status }}
    steps:
      - name: ğŸ“‹ Checkout code with full history
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Run preflight cross-component install check
        run: ./.github/preflight/check_cross_component_installs.sh
          
      - name: ğŸ” Enhanced Security Scan
        id: security
        run: |
          echo "::group::ğŸ›¡ï¸ Security Vulnerability Scan"
          
          # Enhanced sensitive data detection
          echo "ğŸ” Scanning for sensitive data patterns..."
          
          VIOLATIONS=()
          
          # API Keys and Secrets (exclude test fixtures which may intentionally contain fake keys)
          if grep -r -E "(api[_-]?key|password|secret|token)" --include="*.js" --include="*.py" --include="*.json" --exclude-dir=node_modules --exclude-dir=__pycache__ --exclude-dir=test --exclude-dir=tests . | grep -v "# This is a test" | grep -v "placeholder" | grep -v "example"; then
            VIOLATIONS+=("ğŸš¨ CRITICAL: Potential API keys or secrets found in source code")
          fi
          
          # Internal IP addresses (exclude test fixtures)
          if grep -r -E "(10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.)" --include="*.js" --include="*.py" --include="*.yml" --include="*.yaml" --exclude-dir=node_modules --exclude-dir=test --exclude-dir=tests .; then
            VIOLATIONS+=("âš ï¸ WARNING: Internal IP addresses found - ensure these are not production IPs")
          fi
          
          # Database connection strings
          if grep -r -E "(mongodb://|mysql://|postgresql://|redis://)" --include="*.js" --include="*.py" --include="*.env*" --exclude-dir=node_modules --exclude-dir=test --exclude-dir=tests .; then
            VIOLATIONS+=("ğŸš¨ CRITICAL: Database connection strings found in source code")
          fi
          
          # AWS keys pattern
          if grep -r -E "(AKIA[0-9A-Z]{16})" --include="*.js" --include="*.py" --include="*.json" --exclude-dir=node_modules --exclude-dir=test --exclude-dir=tests .; then
            VIOLATIONS+=("ğŸš¨ CRITICAL: AWS access keys found in source code")
          fi
          
          # Report violations with enhanced messaging
          if [ ${#VIOLATIONS[@]} -gt 0 ]; then
            echo "âŒ SECURITY VIOLATIONS DETECTED:"
            for violation in "${VIOLATIONS[@]}"; do
              echo "  $violation"
            done
            echo ""
            echo "ğŸ”§ REMEDIATION STEPS:"
            echo "  1. Remove sensitive data from source code"
            echo "  2. Use environment variables or secret management"
            echo "  3. Add patterns to .gitignore if needed"
            echo "  4. Consider using git-secrets or similar tools"
            echo ""
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "âœ… No security violations detected"
            echo "status=passed" >> $GITHUB_OUTPUT
          fi
          echo "::endgroup::"

      - name: ğŸ“¦ Dependency Vulnerability Check
        id: deps
        run: |
          echo "::group::ğŸ“¦ Dependency Security Analysis"
          
          # Check Python dependencies
          if [ -f "backend/requirements.txt" ]; then
            echo "ğŸ Analyzing Python dependencies..."
            pip install safety
            if ! safety check -r backend/requirements.txt --json; then
              echo "âŒ PYTHON DEPENDENCY VULNERABILITIES FOUND"
              echo ""
              echo "ğŸ”§ REMEDIATION:"
              echo "  1. Review the vulnerability report above"
              echo "  2. Update affected packages: pip install -U package_name"
              echo "  3. Test thoroughly after updates"
              echo "  4. Consider using pip-audit for ongoing monitoring"
              echo "status=failed" >> $GITHUB_OUTPUT
              exit 1
            fi
          fi
          
          # Check Node.js dependencies
          if [ -f "frontend/package.json" ]; then
            echo "ğŸ“¦ Analyzing Node.js dependencies..."
            cd frontend
            npm audit --audit-level=high --json > audit-results.json || true
            
            if [ -s audit-results.json ] && [ "$(cat audit-results.json | jq '.metadata.vulnerabilities.high + .metadata.vulnerabilities.critical')" != "0" ]; then
              echo "âŒ NODE.JS DEPENDENCY VULNERABILITIES FOUND"
              echo ""
              echo "ğŸ“Š Vulnerability Summary:"
              cat audit-results.json | jq '.metadata.vulnerabilities'
              echo ""
              echo "ğŸ”§ REMEDIATION:"
              echo "  1. Run: npm audit fix"
              echo "  2. For breaking changes: npm audit fix --force"
              echo "  3. Update package.json manually if needed"
              echo "  4. Test application thoroughly"
              echo "status=failed" >> $GITHUB_OUTPUT
              exit 1
            fi
            cd ..
          fi
          
          echo "âœ… No critical dependency vulnerabilities found"
          echo "status=passed" >> $GITHUB_OUTPUT
          echo "::endgroup::"

      - name: ğŸ§¹ Code Quality & Linting
        id: lint
        run: |
          echo "::group::ğŸ§¹ Code Quality Analysis"
          
          LINT_ERRORS=()
          
          # Python linting
          if [ -f "backend/requirements.txt" ]; then
            echo "ğŸ Analyzing Python code quality..."
            pip install flake8 black isort mypy
            
            # Check Python formatting
            if ! black --check backend/ --diff; then
              LINT_ERRORS+=("Python code formatting issues found - run 'black backend/' to fix")
            fi
            
            # Check import sorting
            if ! isort --check-only backend/ --diff; then
              LINT_ERRORS+=("Python import sorting issues found - run 'isort backend/' to fix")
            fi
            
            # Basic linting
            if ! flake8 backend/ --max-line-length=120 --extend-ignore=E203,W503; then
              LINT_ERRORS+=("Python linting issues found - see flake8 output above")
            fi
          fi
          
          # JavaScript/TypeScript linting
          if [ -f "frontend/package.json" ]; then
            echo "ğŸ“¦ Analyzing JavaScript/TypeScript code quality..."
            cd frontend
            npm install
            
            if ! npm run lint 2>/dev/null; then
              LINT_ERRORS+=("JavaScript/TypeScript linting issues found - run 'npm run lint:fix' to fix")
            fi
            cd ..
          fi
          
          # Report linting issues
          if [ ${#LINT_ERRORS[@]} -gt 0 ]; then
            echo "âŒ CODE QUALITY ISSUES DETECTED:"
            for error in "${LINT_ERRORS[@]}"; do
              echo "  ğŸ”¸ $error"
            done
            echo ""
            echo "ğŸ”§ QUICK FIXES:"
            echo "  1. Run the suggested commands above"
            echo "  2. Configure your IDE for automatic formatting"
            echo "  3. Consider pre-commit hooks for consistent quality"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "âœ… Code quality checks passed"
            echo "status=passed" >> $GITHUB_OUTPUT
          fi
          echo "::endgroup::"

  # Enhanced backend testing with better error reporting
  backend-tests:
    name: ğŸ Backend Testing & Validation
    runs-on: ubuntu-latest
    needs: preflight-checks
    services:
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        env:
          discovery.type: single-node
          xpack.security.enabled: false
          ES_JAVA_OPTS: -Xms512m -Xmx512m
        ports:
          - 9200:9200
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

    steps:
      - name: ğŸ“‹ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Setup Python with enhanced caching
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: backend/requirements.txt

      - name: ğŸ“¦ Install dependencies with error handling
        run: |
          echo "::group::ğŸ“¦ Installing Python Dependencies"
          cd backend
          
          # Upgrade pip first
          python -m pip install --upgrade pip
          
          # Install dependencies with detailed error reporting
          if ! pip install -r requirements.txt; then
            echo "âŒ DEPENDENCY INSTALLATION FAILED"
            echo ""
            echo "ğŸ”§ TROUBLESHOOTING STEPS:"
            echo "  1. Check requirements.txt for conflicting versions"
            echo "  2. Try installing packages individually to isolate issues"
            echo "  3. Check for platform-specific dependencies"
            echo "  4. Verify Python version compatibility"
            echo ""
            echo "ğŸ“Š Environment Info:"
            echo "  Python Version: $(python --version)"
            echo "  Pip Version: $(pip --version)"
            echo "  Platform: $(uname -a)"
            exit 1
          fi
          
          # Install test dependencies
          pip install pytest pytest-asyncio pytest-cov httpx
          echo "âœ… Dependencies installed successfully"
          echo "::endgroup::"

      - name: ğŸ” Elasticsearch Service Validation
        run: |
          echo "::group::ğŸ” Validating Elasticsearch Service"
          
          # Wait for Elasticsearch to be ready
          echo "â³ Waiting for Elasticsearch to be ready..."
          for i in {1..30}; do
            if curl -f http://localhost:9200/_cluster/health >/dev/null 2>&1; then
              echo "âœ… Elasticsearch is ready"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "âŒ ELASTICSEARCH STARTUP FAILED"
              echo ""
              echo "ğŸ”§ TROUBLESHOOTING:"
              echo "  1. Check Elasticsearch logs: docker logs <container_id>"
              echo "  2. Verify service configuration in workflow"
              echo "  3. Check port availability and networking"
              echo "  4. Ensure sufficient memory allocation"
              echo ""
              echo "ğŸ“Š Current Status:"
              curl -s http://localhost:9200/_cluster/health || echo "Connection failed"
              exit 1
            fi
            echo "  Attempt $i/30 - waiting..."
            sleep 2
          done
          
          # Validate cluster health
          HEALTH=$(curl -s http://localhost:9200/_cluster/health | jq -r '.status')
          echo "ğŸ“Š Cluster Health: $HEALTH"
          
          if [ "$HEALTH" != "green" ] && [ "$HEALTH" != "yellow" ]; then
            echo "âŒ Elasticsearch cluster is not healthy (status: $HEALTH)"
            exit 1
          fi
          echo "::endgroup::"

      - name: ğŸ§ª Run Backend Tests with Enhanced Reporting
        run: |
          echo "::group::ğŸ§ª Backend Test Execution"
          cd backend
          
          # Set test environment variables
          export ELASTICSEARCH_URL=http://localhost:9200
          export ENVIRONMENT=test
          export LOG_LEVEL=DEBUG
          
          # Run tests with comprehensive reporting
          echo "ğŸƒ Running test suite..."
          
          if ! python -m pytest \
            --cov=. \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=80 \
            --tb=short \
            --durations=10 \
            -v \
            ../test/; then
            
            echo ""
            echo "âŒ BACKEND TESTS FAILED"
            echo ""
            echo "ğŸ”§ DEBUGGING STEPS:"
            echo "  1. Check test output above for specific failures"
            echo "  2. Run tests locally: cd backend && python -m pytest ../test/ -v"
            echo "  3. Check Elasticsearch connectivity: curl http://localhost:9200"
            echo "  4. Verify environment variables are set correctly"
            echo "  5. Check for import errors or missing dependencies"
            echo ""
            echo "ğŸ“Š Test Environment:"
            echo "  Python Version: $(python --version)"
            echo "  Pytest Version: $(python -m pytest --version)"
            echo "  Elasticsearch URL: $ELASTICSEARCH_URL"
            echo "  Environment: $ENVIRONMENT"
            exit 1
          fi
          
          echo "âœ… All backend tests passed successfully"
          echo "::endgroup::"

      - name: ğŸ“Š Upload Coverage Reports
        uses: codecov/codecov-action@v3
        if: always()
        with:
          file: backend/coverage.xml
          flags: backend
          name: backend-coverage

  # Enhanced frontend testing
  frontend-tests:
    name: ğŸ“¦ Frontend Testing & Build Validation
    runs-on: ubuntu-latest
    needs: preflight-checks
    steps:
      - name: ğŸ“‹ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup Node.js with enhanced caching
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: ğŸ“¦ Install Frontend Dependencies
        run: |
          echo "::group::ğŸ“¦ Installing Frontend Dependencies"
          cd frontend
          
          # Clean install for consistency
          if ! npm ci; then
            echo "âŒ FRONTEND DEPENDENCY INSTALLATION FAILED"
            echo ""
            echo "ğŸ”§ TROUBLESHOOTING STEPS:"
            echo "  1. Delete package-lock.json and node_modules"
            echo "  2. Run 'npm install' to regenerate lock file"
            echo "  3. Check for conflicting peer dependencies"
            echo "  4. Verify Node.js version compatibility"
            echo ""
            echo "ğŸ“Š Environment Info:"
            echo "  Node Version: $(node --version)"
            echo "  NPM Version: $(npm --version)"
            echo "  Platform: $(uname -a)"
            exit 1
          fi
          
          echo "âœ… Frontend dependencies installed successfully"
          echo "::endgroup::"

      - name: ğŸ§ª Run Frontend Tests
        run: |
          echo "::group::ğŸ§ª Frontend Test Execution"
          cd frontend
          
          if ! npm test -- --coverage --watchAll=false; then
            echo ""
            echo "âŒ FRONTEND TESTS FAILED"
            echo ""
            echo "ğŸ”§ DEBUGGING STEPS:"
            echo "  1. Check test output above for specific failures"
            echo "  2. Run tests locally: cd frontend && npm test"
            echo "  3. Check for component rendering issues"
            echo "  4. Verify mock configurations"
            echo "  5. Ensure test environment is properly configured"
            echo ""
            echo "ğŸ“Š Test Environment:"
            echo "  Node Version: $(node --version)"
            echo "  React Scripts Version: $(npm list react-scripts --depth=0)"
            exit 1
          fi
          
          echo "âœ… All frontend tests passed successfully"
          echo "::endgroup::"

      - name: ğŸ—ï¸ Build Frontend Application
        run: |
          echo "::group::ğŸ—ï¸ Building Frontend Application"
          cd frontend
          
          if ! npm run build; then
            echo ""
            echo "âŒ FRONTEND BUILD FAILED"
            echo ""
            echo "ğŸ”§ DEBUGGING STEPS:"
            echo "  1. Check build output above for specific errors"
            echo "  2. Run build locally: cd frontend && npm run build"
            echo "  3. Check for TypeScript errors"
            echo "  4. Verify environment variables"
            echo "  5. Check for missing dependencies or imports"
            echo ""
            echo "ğŸ“Š Build Environment:"
            echo "  Node Version: $(node --version)"
            echo "  Available Memory: $(free -h)"
            echo "  Disk Space: $(df -h)"
            exit 1
          fi
          
          echo "âœ… Frontend build completed successfully"
          echo "::endgroup::"

  # Enhanced integration testing
  integration-tests:
    name: ğŸ”— Integration & E2E Testing
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests]
    services:
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        env:
          discovery.type: single-node
          xpack.security.enabled: false
        ports:
          - 9200:9200

    steps:
      - name: ğŸ“‹ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ³ Build and Start Application Stack
        run: |
          echo "::group::ğŸ³ Application Stack Startup"
          
          # Build the application
          if ! docker-compose -f docker-compose.yml build; then
            echo "âŒ APPLICATION BUILD FAILED"
            echo ""
            echo "ğŸ”§ DEBUGGING STEPS:"
            echo "  1. Check Dockerfile syntax in each service"
            echo "  2. Verify base image availability"
            echo "  3. Check for missing files in build context"
            echo "  4. Review docker-compose.yml configuration"
            exit 1
          fi
          
          # Start the application
          if ! docker-compose -f docker-compose.yml up -d; then
            echo "âŒ APPLICATION STARTUP FAILED"
            echo ""
            echo "ğŸ”§ DEBUGGING STEPS:"
            echo "  1. Check service logs: docker-compose logs <service>"
            echo "  2. Verify port availability"
            echo "  3. Check environment variable configuration"
            echo "  4. Ensure all dependencies are available"
            echo ""
            echo "ğŸ“Š Container Status:"
            docker-compose ps
            exit 1
          fi
          
          echo "âœ… Application stack started successfully"
          echo "::endgroup::"

      - name: â³ Wait for Services to be Ready
        run: |
          echo "::group::â³ Service Health Checks"
          
          # Wait for backend
          echo "ğŸ” Waiting for backend service..."
          for i in {1..60}; do
            if curl -f http://localhost:8000/health >/dev/null 2>&1; then
              echo "âœ… Backend service is ready"
              break
            fi
            if [ $i -eq 60 ]; then
              echo "âŒ BACKEND SERVICE FAILED TO START"
              echo ""
              echo "ğŸ“Š Service Logs:"
              docker-compose logs backend
              exit 1
            fi
            sleep 2
          done
          
          # Wait for frontend
          echo "ğŸ” Waiting for frontend service..."
          for i in {1..60}; do
            if curl -f http://localhost:3000 >/dev/null 2>&1; then
              echo "âœ… Frontend service is ready"
              break
            fi
            if [ $i -eq 60 ]; then
              echo "âŒ FRONTEND SERVICE FAILED TO START"
              echo ""
              echo "ğŸ“Š Service Logs:"
              docker-compose logs frontend
              exit 1
            fi
            sleep 2
          done
          
          echo "âœ… All services are ready"
          echo "::endgroup::"

      - name: ğŸ§ª Run Integration Tests
        run: |
          echo "::group::ğŸ§ª Integration Test Execution"
          
          # Basic API endpoint tests
          echo "ğŸ” Testing API endpoints..."
          
          # Test health endpoint
          if ! curl -f http://localhost:8000/health; then
            echo "âŒ Health endpoint failed"
            exit 1
          fi
          
          # Test query endpoint
          if ! curl -f -X POST http://localhost:8000/query \
            -H "Content-Type: application/json" \
            -d '{"index": "test", "query": {"match_all": {}}}'; then
            echo "âŒ Query endpoint failed"
            exit 1
          fi
          
          echo "âœ… Integration tests completed successfully"
          echo "::endgroup::"

      - name: ğŸ§¹ Cleanup
        if: always()
        run: |
          echo "ğŸ§¹ Cleaning up test environment..."
          docker-compose down -v
          docker system prune -f

  # Enhanced deployment readiness check
  deployment-readiness:
    name: ğŸš€ Deployment Readiness Assessment
    runs-on: ubuntu-latest
    needs: [preflight-checks, backend-tests, frontend-tests, integration-tests]
    if: github.ref == 'refs/heads/main'
    steps:
      - name: ğŸ“‹ Deployment Readiness Report
        run: |
          echo "::group::ğŸš€ Deployment Readiness Report"
          
          echo "âœ… DEPLOYMENT READINESS CHECKLIST:"
          echo "  ğŸ”’ Security scans: PASSED"
          echo "  ğŸ§ª Backend tests: PASSED"
          echo "  ğŸ“¦ Frontend tests: PASSED"
          echo "  ğŸ”— Integration tests: PASSED"
          echo "  ğŸ“Š Code coverage: ADEQUATE"
          echo "  ğŸ—ï¸ Build verification: PASSED"
          echo ""
          echo "ğŸ¯ Ready for deployment to production!"
          echo ""
          echo "ğŸ“‹ Post-deployment verification steps:"
          echo "  1. Monitor application health endpoints"
          echo "  2. Check error rates and response times"
          echo "  3. Verify all integrations are working"
          echo "  4. Run smoke tests on production"
          echo "  5. Monitor logs for any anomalies"
          echo "::endgroup::"

      - name: ğŸ·ï¸ Create Release Tag
        if: success()
        run: |
          echo "ğŸ·ï¸ Creating release tag for successful deployment..."
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Generate version based on timestamp
          VERSION="v$(date +'%Y.%m.%d')-${{ github.run_number }}"
          git tag -a $VERSION -m "Automated release $VERSION"
          git push origin $VERSION || true
          
          echo "âœ… Release tag $VERSION created successfully"
